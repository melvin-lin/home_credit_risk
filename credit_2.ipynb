{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d742c75",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 5.558572,
     "end_time": "2024-04-16T09:47:10.558709",
     "exception": false,
     "start_time": "2024-04-16T09:47:05.000137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import os\n",
    "import gc\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ROOT = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b97f0e",
   "metadata": {
    "papermill": {
     "duration": 0.978947,
     "end_time": "2024-04-16T09:47:11.542855",
     "exception": false,
     "start_time": "2024-04-16T09:47:10.563908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘home-credit-lgb’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir home-credit-lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79b6a6ad",
   "metadata": {
    "papermill": {
     "duration": 0.030592,
     "end_time": "2024-04-16T09:47:11.577883",
     "exception": false,
     "start_time": "2024-04-16T09:47:11.547291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "\n",
    "    def set_table_dtypes(df):\n",
    "        for col in df.columns:\n",
    "            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Int64))\n",
    "            elif col in [\"date_decision\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))\n",
    "            elif col[-1] in (\"P\", \"A\"):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Float64))\n",
    "            elif col[-1] in (\"M\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.String))\n",
    "            elif col[-1] in (\"D\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))\n",
    "        return df\n",
    "\n",
    "    def handle_dates(df):\n",
    "        for col in df.columns:\n",
    "            if col[-1] in (\"D\",):\n",
    "                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))  #!!?\n",
    "                df = df.with_columns(pl.col(col).dt.total_days()) # t - t-1\n",
    "        df = df.drop(\"date_decision\", \"MONTH\")\n",
    "        return df\n",
    "\n",
    "    def filter_cols(df):\n",
    "        for col in df.columns:\n",
    "            if col not in [\"target\", \"case_id\", \"WEEK_NUM\"]:\n",
    "                isnull = df[col].is_null().mean()\n",
    "                if isnull > 0.7:\n",
    "                    df = df.drop(col)\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if (col not in [\"target\", \"case_id\", \"WEEK_NUM\"]) & (df[col].dtype == pl.String):\n",
    "                freq = df[col].n_unique()\n",
    "                if (freq == 1) | (freq > 200):\n",
    "                    df = df.drop(col)\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "class Aggregator:\n",
    "    # Please add or subtract features yourself, be aware that too many features will take up too much space.\n",
    "    def num_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"P\", \"A\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n",
    "        expr_median = [pl.median(col).alias(f\"median_{col}\") for col in cols]\n",
    "        expr_var = [pl.var(col).alias(f\"var_{col}\") for col in cols]\n",
    "\n",
    "        return expr_max + expr_last + expr_mean \n",
    "\n",
    "    def date_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"D\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        # expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n",
    "        expr_median = [pl.median(col).alias(f\"median_{col}\") for col in cols]\n",
    "\n",
    "        return expr_max + expr_last + expr_mean \n",
    "\n",
    "    def str_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"M\",)]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        # expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        # expr_count = [pl.count(col).alias(f\"count_{col}\") for col in cols]\n",
    "        return expr_max + expr_last  # +expr_count\n",
    "\n",
    "    def other_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"T\", \"L\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        # expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        return expr_max + expr_last\n",
    "\n",
    "    def count_expr(df):\n",
    "        cols = [col for col in df.columns if \"num_group\" in col]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        # expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        return expr_max + expr_last\n",
    "\n",
    "    def get_exprs(df):\n",
    "        exprs = Aggregator.num_expr(df) + \\\n",
    "                Aggregator.date_expr(df) + \\\n",
    "                Aggregator.str_expr(df) + \\\n",
    "                Aggregator.other_expr(df) + \\\n",
    "                Aggregator.count_expr(df)\n",
    "\n",
    "        return exprs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4b9f265",
   "metadata": {
    "papermill": {
     "duration": 0.015257,
     "end_time": "2024-04-16T09:47:11.597254",
     "exception": false,
     "start_time": "2024-04-16T09:47:11.581997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_file(path, depth=None):\n",
    "    df = pl.read_parquet(path)\n",
    "    df = df.pipe(Pipeline.set_table_dtypes)\n",
    "    if depth in [1,2]:\n",
    "        df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df)) \n",
    "    return df\n",
    "\n",
    "\n",
    "def read_files(regex_path, depth=None):\n",
    "    chunks = []\n",
    "    \n",
    "    for path in glob(str(regex_path)):\n",
    "        df = pl.read_parquet(path)\n",
    "        df = df.pipe(Pipeline.set_table_dtypes)\n",
    "        if depth in [1, 2]:\n",
    "            df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n",
    "        chunks.append(df)\n",
    "    \n",
    "    df = pl.concat(chunks, how=\"vertical_relaxed\")\n",
    "    df = df.unique(subset=[\"case_id\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "325b7023",
   "metadata": {
    "papermill": {
     "duration": 0.018378,
     "end_time": "2024-04-16T09:47:11.620814",
     "exception": false,
     "start_time": "2024-04-16T09:47:11.602436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_eng(df_base, depth_0, depth_1, depth_2):\n",
    "    df_base = (\n",
    "        df_base\n",
    "        .with_columns(\n",
    "            month_decision = pl.col(\"date_decision\").dt.month(),\n",
    "            weekday_decision = pl.col(\"date_decision\").dt.weekday(),\n",
    "        )\n",
    "    )\n",
    "    for i, df in enumerate(depth_0 + depth_1 + depth_2):\n",
    "        df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n",
    "    df_base = df_base.pipe(Pipeline.handle_dates)\n",
    "    return df_base\n",
    "\n",
    "\n",
    "def to_pandas(df_data, cat_cols=None):\n",
    "    df_data = df_data.to_pandas()\n",
    "    if cat_cols is None:\n",
    "        cat_cols = list(df_data.select_dtypes(\"object\").columns)\n",
    "    df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n",
    "    return df_data, cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89f8c688",
   "metadata": {
    "papermill": {
     "duration": 0.023931,
     "end_time": "2024-04-16T09:47:11.649064",
     "exception": false,
     "start_time": "2024-04-16T09:47:11.625133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if str(col_type)==\"category\":\n",
    "            continue\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            continue\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af4fcc6a",
   "metadata": {
    "papermill": {
     "duration": 135.156456,
     "end_time": "2024-04-16T09:49:26.812025",
     "exception": false,
     "start_time": "2024-04-16T09:47:11.655569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROOT            = Path(ROOT)\n",
    "\n",
    "TRAIN_DIR       = ROOT / \"parquet_files\" / \"train\"\n",
    "TEST_DIR        = ROOT / \"parquet_files\" / \"test\"\n",
    "\n",
    "data_store = {\n",
    "    \"df_base\": read_file(TRAIN_DIR / \"train_base.parquet\"),\n",
    "    \"depth_0\": [\n",
    "        read_file(TRAIN_DIR / \"train_static_cb_0.parquet\"),\n",
    "        read_files(TRAIN_DIR / \"train_static_0_*.parquet\"),\n",
    "    ],\n",
    "    \"depth_1\": [\n",
    "        read_files(TRAIN_DIR / \"train_applprev_1_*.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_a_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_b_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_c_1.parquet\", 1),\n",
    "        read_files(TRAIN_DIR / \"train_credit_bureau_a_1_*.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_credit_bureau_b_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_other_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_person_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_deposit_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_debitcard_1.parquet\", 1),\n",
    "    ],\n",
    "    \"depth_2\": [\n",
    "        read_file(TRAIN_DIR / \"train_credit_bureau_b_2.parquet\", 2),\n",
    "        read_files(TRAIN_DIR / \"train_credit_bureau_a_2_*.parquet\", 2),\n",
    "        read_file(TRAIN_DIR / \"train_applprev_2.parquet\", 2),\n",
    "        read_file(TRAIN_DIR / \"train_person_2.parquet\", 2)\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5debed1a",
   "metadata": {
    "papermill": {
     "duration": 21.14201,
     "end_time": "2024-04-16T09:49:47.958912",
     "exception": false,
     "start_time": "2024-04-16T09:49:26.816902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape:\t (1526659, 861)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = feature_eng(**data_store)\n",
    "print(\"train data shape:\\t\", df_train.shape)\n",
    "del data_store\n",
    "df_train = df_train.pipe(Pipeline.filter_cols)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f114715",
   "metadata": {
    "papermill": {
     "duration": 77.401588,
     "end_time": "2024-04-16T09:51:05.365456",
     "exception": false,
     "start_time": "2024-04-16T09:49:47.963868",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 4322.75 MB\n",
      "Memory usage after optimization is: 1528.81 MB\n",
      "Decreased by 64.6%\n",
      "train data shape:\t (1526659, 472)\n",
      "Use these ['case_id', 'WEEK_NUM', 'target', 'month_decision', 'weekday_decision', 'credamount_770A', 'applicationcnt_361L', 'applications30d_658L', 'applicationscnt_1086L', 'applicationscnt_464L', 'applicationscnt_867L', 'clientscnt_1022L', 'clientscnt_100L', 'clientscnt_1071L', 'clientscnt_1130L', 'clientscnt_157L', 'clientscnt_257L', 'clientscnt_304L', 'clientscnt_360L', 'clientscnt_493L', 'clientscnt_533L', 'clientscnt_887L', 'clientscnt_946L', 'deferredmnthsnum_166L', 'disbursedcredamount_1113A', 'downpmt_116A', 'homephncnt_628L', 'isbidproduct_1095L', 'mobilephncnt_593L', 'numactivecreds_622L', 'numactivecredschannel_414L', 'numactiverelcontr_750L', 'numcontrs3months_479L', 'numnotactivated_1143L', 'numpmtchanneldd_318L', 'numrejects9m_859L', 'sellerplacecnt_915L', 'max_mainoccupationinc_384A', 'max_birth_259D', 'max_num_group1_9']\n",
      "####### NAN count = 0\n",
      "####### NAN count = 918788\n",
      "Use these ['dateofbirth_337D', 'days180_256L', 'days30_165L', 'days360_512L', 'firstquarter_103L', 'fourthquarter_440L', 'secondquarter_766L', 'thirdquarter_1082L', 'max_debtoutstand_525A', 'max_debtoverdue_47A', 'max_refreshdate_3813885D', 'mean_refreshdate_3813885D']\n",
      "####### NAN count = 140968\n",
      "Use these ['pmtscount_423L', 'pmtssum_45A']\n",
      "####### NAN count = 954021\n",
      "####### NAN count = 806659\n",
      "####### NAN count = 866332\n",
      "####### NAN count = 418178\n",
      "Use these ['amtinstpaidbefduel24m_4187115A', 'numinstlswithdpd5_4187116L']\n",
      "####### NAN count = 561124\n",
      "Use these ['annuitynextmonth_57A', 'currdebt_22A', 'currdebtcredtyperange_828A', 'numinstls_657L', 'totalsettled_863A']\n",
      "####### NAN count = 4\n",
      "Use these ['mindbddpdlast24m_3658935P']\n",
      "####### NAN count = 613202\n",
      "####### NAN count = 948244\n",
      "Use these ['mindbdtollast24m_4525191P']\n",
      "####### NAN count = 972827\n",
      "####### NAN count = 467175\n",
      "Use these ['avginstallast24m_3658937A', 'maxinstallast24m_3658928A']\n",
      "####### NAN count = 624875\n",
      "####### NAN count = 757006\n",
      "####### NAN count = 841181\n",
      "####### NAN count = 1026987\n",
      "####### NAN count = 455190\n",
      "####### NAN count = 460822\n",
      "Use these ['commnoinclast6m_3546845L', 'maxdpdfrom6mto36m_3546853P']\n",
      "####### NAN count = 343375\n",
      "####### NAN count = 833735\n",
      "####### NAN count = 887659\n",
      "Use these ['daysoverduetolerancedd_3976961L', 'numinsttopaygr_769L']\n",
      "####### NAN count = 452594\n",
      "####### NAN count = 977119\n",
      "Use these ['eir_270L']\n",
      "####### NAN count = 190833\n",
      "####### NAN count = 859214\n",
      "####### NAN count = 482103\n",
      "####### NAN count = 453587\n",
      "Use these ['lastapplicationdate_877D', 'mean_creationdate_885D', 'max_num_group1', 'last_num_group1', 'max_num_group2_14', 'last_num_group2_14']\n",
      "####### NAN count = 305137\n",
      "Use these ['lastapprcredamount_781A', 'lastapprdate_640D']\n",
      "####### NAN count = 442041\n",
      "####### NAN count = 977975\n",
      "Use these ['lastrejectcredamount_222A', 'lastrejectdate_50D']\n",
      "####### NAN count = 769046\n",
      "####### NAN count = 511255\n",
      "Use these ['mastercontrelectronic_519L', 'mastercontrexist_109L', 'maxannuity_159A', 'maxdebt4_972A', 'maxdpdlast24m_143P', 'maxdpdlast3m_392P', 'maxdpdtolerance_374P']\n",
      "####### NAN count = 306019\n",
      "####### NAN count = 960953\n",
      "####### NAN count = 705504\n",
      "####### NAN count = 876276\n",
      "####### NAN count = 826000\n",
      "####### NAN count = 829402\n",
      "####### NAN count = 1032856\n",
      "####### NAN count = 766958\n",
      "Use these ['numinstpaidearly_338L', 'numinstpaidearly5d_1087L', 'numinstpaidlate1d_3546852L']\n",
      "####### NAN count = 452593\n",
      "####### NAN count = 455081\n",
      "Use these ['numinstlsallpaid_934L']\n",
      "####### NAN count = 445669\n",
      "Use these ['numinstlswithdpd10_728L', 'numinstlswithoutdpd_562L']\n",
      "####### NAN count = 456495\n",
      "Use these ['numinstpaid_4499208L']\n",
      "####### NAN count = 847191\n",
      "####### NAN count = 446983\n",
      "Use these ['numinstregularpaidest_4493210L', 'numinstpaidearly5dest_4493211L', 'sumoutstandtotalest_4493215A']\n",
      "####### NAN count = 840646\n",
      "####### NAN count = 669186\n",
      "####### NAN count = 455612\n",
      "Use these ['pctinstlsallpaidearl3d_427L', 'pctinstlsallpaidlate1d_3546856L']\n",
      "####### NAN count = 458738\n",
      "####### NAN count = 461362\n",
      "####### NAN count = 459827\n",
      "####### NAN count = 460079\n",
      "####### NAN count = 44954\n",
      "####### NAN count = 78526\n",
      "####### NAN count = 131888\n",
      "####### NAN count = 181122\n",
      "####### NAN count = 223240\n",
      "####### NAN count = 445320\n",
      "####### NAN count = 3\n",
      "Use these ['mean_actualdpd_943P']\n",
      "####### NAN count = 305154\n",
      "Use these ['max_annuity_853A', 'mean_annuity_853A']\n",
      "####### NAN count = 308739\n",
      "Use these ['max_credacc_credlmt_575A', 'max_credamount_590A', 'max_downpmt_134A', 'mean_credacc_credlmt_575A', 'mean_credamount_590A', 'mean_downpmt_134A']\n",
      "####### NAN count = 307441\n",
      "Use these ['max_currdebt_94A', 'mean_currdebt_94A']\n",
      "####### NAN count = 419006\n",
      "Use these ['max_mainoccupationinc_437A', 'mean_mainoccupationinc_437A']\n",
      "####### NAN count = 306361\n",
      "Use these ['mean_maxdpdtolerance_577P']\n",
      "####### NAN count = 450969\n",
      "Use these ['max_outstandingdebt_522A', 'mean_outstandingdebt_522A']\n",
      "####### NAN count = 420383\n",
      "####### NAN count = 307551\n",
      "####### NAN count = 477657\n",
      "####### NAN count = 433335\n",
      "Use these ['last_credamount_590A', 'last_downpmt_134A']\n",
      "####### NAN count = 438219\n",
      "####### NAN count = 824731\n",
      "####### NAN count = 312491\n",
      "####### NAN count = 899665\n",
      "####### NAN count = 827764\n",
      "Use these ['max_approvaldate_319D', 'mean_approvaldate_319D']\n",
      "####### NAN count = 442999\n",
      "Use these ['max_dateactivated_425D', 'mean_dateactivated_425D']\n",
      "####### NAN count = 454678\n",
      "Use these ['max_dtlastpmt_581D', 'mean_dtlastpmt_581D']\n",
      "####### NAN count = 703840\n",
      "Use these ['max_dtlastpmtallstes_3545839D', 'mean_dtlastpmtallstes_3545839D']\n",
      "####### NAN count = 548987\n",
      "Use these ['max_employedfrom_700D']\n",
      "####### NAN count = 559169\n",
      "Use these ['max_firstnonzeroinstldate_307D', 'mean_firstnonzeroinstldate_307D']\n",
      "####### NAN count = 334873\n",
      "####### NAN count = 891021\n",
      "####### NAN count = 305203\n",
      "####### NAN count = 920818\n",
      "####### NAN count = 1016761\n",
      "####### NAN count = 1050001\n",
      "####### NAN count = 485683\n",
      "####### NAN count = 961606\n",
      "####### NAN count = 552766\n",
      "Use these ['max_pmtnum_8L']\n",
      "####### NAN count = 321446\n",
      "Use these ['last_pmtnum_8L']\n",
      "####### NAN count = 482174\n",
      "Use these ['max_pmtamount_36A', 'last_pmtamount_36A', 'max_processingdate_168D', 'last_processingdate_168D', 'max_num_group1_5']\n",
      "####### NAN count = 1044394\n",
      "Use these ['mean_credlmt_230A']\n",
      "####### NAN count = 1036944\n",
      "Use these ['mean_credlmt_935A']\n",
      "####### NAN count = 603001\n",
      "Use these ['mean_pmts_dpd_1073P', 'max_dpdmaxdatemonth_89T', 'max_dpdmaxdateyear_596T']\n",
      "####### NAN count = 263166\n",
      "Use these ['max_pmts_dpd_303P', 'mean_dpdmax_757P', 'max_dpdmaxdatemonth_442T', 'max_dpdmaxdateyear_896T', 'mean_pmts_dpd_303P']\n",
      "####### NAN count = 514070\n",
      "Use these ['mean_instlamount_768A']\n",
      "####### NAN count = 606920\n",
      "Use these ['mean_monthlyinstlamount_332A']\n",
      "####### NAN count = 263233\n",
      "Use these ['max_monthlyinstlamount_674A', 'mean_monthlyinstlamount_674A']\n",
      "####### NAN count = 517511\n",
      "Use these ['mean_outstandingamount_354A']\n",
      "####### NAN count = 545885\n",
      "Use these ['mean_outstandingamount_362A']\n",
      "####### NAN count = 636453\n",
      "Use these ['mean_overdueamount_31A']\n",
      "####### NAN count = 512650\n",
      "Use these ['mean_overdueamount_659A', 'max_numberofoverdueinstls_725L']\n",
      "####### NAN count = 263171\n",
      "Use these ['mean_overdueamountmax2_14A', 'mean_totaloutstanddebtvalue_39A', 'mean_dateofcredend_289D', 'mean_dateofcredstart_739D', 'max_lastupdate_1112D', 'mean_lastupdate_1112D', 'max_numberofcontrsvalue_258L', 'max_numberofoverdueinstlmax_1039L', 'max_overdueamountmaxdatemonth_365T', 'max_overdueamountmaxdateyear_2T', 'mean_pmts_overdue_1140A', 'max_pmts_month_158T', 'max_pmts_year_1139T']\n",
      "####### NAN count = 262653\n",
      "Use these ['mean_overdueamountmax2_398A', 'max_dateofcredend_353D', 'max_dateofcredstart_181D', 'mean_dateofcredend_353D', 'max_numberofoverdueinstlmax_1151L']\n",
      "####### NAN count = 512590\n",
      "Use these ['mean_overdueamountmax_35A', 'max_overdueamountmaxdatemonth_284T', 'max_overdueamountmaxdateyear_994T', 'mean_pmts_overdue_1152A']\n",
      "####### NAN count = 513987\n",
      "Use these ['max_residualamount_488A']\n",
      "####### NAN count = 1039597\n",
      "Use these ['mean_residualamount_856A']\n",
      "####### NAN count = 606900\n",
      "Use these ['max_totalamount_6A', 'mean_totalamount_6A']\n",
      "####### NAN count = 545855\n",
      "Use these ['mean_totalamount_996A']\n",
      "####### NAN count = 636448\n",
      "Use these ['mean_totaldebtoverduevalue_718A', 'mean_totaloutstanddebtvalue_668A', 'max_numberofcontrsvalue_358L']\n",
      "####### NAN count = 297072\n",
      "Use these ['max_dateofrealrepmt_138D', 'mean_dateofrealrepmt_138D']\n",
      "####### NAN count = 512961\n",
      "Use these ['max_lastupdate_388D', 'mean_lastupdate_388D']\n",
      "####### NAN count = 512591\n",
      "Use these ['max_numberofoverdueinstlmaxdat_148D']\n",
      "####### NAN count = 802351\n",
      "Use these ['mean_numberofoverdueinstlmaxdat_641D']\n",
      "####### NAN count = 1012361\n",
      "Use these ['mean_overdueamountmax2date_1002D']\n",
      "####### NAN count = 806653\n",
      "Use these ['max_overdueamountmax2date_1142D']\n",
      "####### NAN count = 1007594\n",
      "####### NAN count = 553734\n",
      "####### NAN count = 822517\n",
      "####### NAN count = 745109\n",
      "####### NAN count = 545898\n",
      "####### NAN count = 636545\n",
      "####### NAN count = 545895\n",
      "####### NAN count = 636544\n",
      "####### NAN count = 512657\n",
      "####### NAN count = 561307\n",
      "####### NAN count = 649082\n",
      "Use these ['last_num_group1_6']\n",
      "####### NAN count = 140386\n",
      "Use these ['last_mainoccupationinc_384A', 'last_birth_259D']\n",
      "####### NAN count = 750301\n",
      "Use these ['max_empl_employedfrom_271D']\n",
      "####### NAN count = 959958\n",
      "Use these ['last_personindex_1023L']\n",
      "####### NAN count = 587206\n",
      "####### NAN count = 772\n",
      "####### NAN count = 262659\n",
      "####### NAN count = 512884\n",
      "Use these ['max_pmts_month_706T', 'max_pmts_year_507T']\n",
      "####### NAN count = 512598\n",
      "Use these ['last_pmts_month_158T', 'last_pmts_year_1139T']\n",
      "####### NAN count = 994041\n",
      "Use these ['last_pmts_month_706T', 'last_pmts_year_507T']\n",
      "####### NAN count = 634357\n",
      "Use these ['max_num_group1_13', 'max_num_group2_13', 'last_num_group2_13']\n",
      "####### NAN count = 141371\n",
      "Use these ['max_num_group1_15', 'max_num_group2_15']\n",
      "####### NAN count = 91554\n",
      "['case_id', 'WEEK_NUM', 'target', 'month_decision', 'weekday_decision', 'credamount_770A', 'applicationcnt_361L', 'applications30d_658L', 'applicationscnt_1086L', 'applicationscnt_464L', 'applicationscnt_867L', 'clientscnt_1022L', 'clientscnt_100L', 'clientscnt_1071L', 'clientscnt_1130L', 'clientscnt_157L', 'clientscnt_257L', 'clientscnt_304L', 'clientscnt_360L', 'clientscnt_493L', 'clientscnt_533L', 'clientscnt_887L', 'clientscnt_946L', 'deferredmnthsnum_166L', 'disbursedcredamount_1113A', 'downpmt_116A', 'homephncnt_628L', 'isbidproduct_1095L', 'mobilephncnt_593L', 'numactivecreds_622L', 'numactivecredschannel_414L', 'numactiverelcontr_750L', 'numcontrs3months_479L', 'numnotactivated_1143L', 'numpmtchanneldd_318L', 'numrejects9m_859L', 'sellerplacecnt_915L', 'max_mainoccupationinc_384A', 'max_birth_259D', 'max_num_group1_9', 'birthdate_574D', 'dateofbirth_337D', 'days180_256L', 'days30_165L', 'days360_512L', 'firstquarter_103L', 'fourthquarter_440L', 'secondquarter_766L', 'thirdquarter_1082L', 'max_debtoutstand_525A', 'max_debtoverdue_47A', 'max_refreshdate_3813885D', 'mean_refreshdate_3813885D', 'pmtscount_423L', 'pmtssum_45A', 'responsedate_1012D', 'responsedate_4527233D', 'actualdpdtolerance_344P', 'amtinstpaidbefduel24m_4187115A', 'numinstlswithdpd5_4187116L', 'annuitynextmonth_57A', 'currdebt_22A', 'currdebtcredtyperange_828A', 'numinstls_657L', 'totalsettled_863A', 'mindbddpdlast24m_3658935P', 'avgdbddpdlast3m_4187120P', 'mindbdtollast24m_4525191P', 'avgdpdtolclosure24_3658938P', 'avginstallast24m_3658937A', 'maxinstallast24m_3658928A', 'avgmaxdpdlast9m_3716943P', 'avgoutstandbalancel6m_4187114A', 'avgpmtlast12m_4525200A', 'cntincpaycont9m_3716944L', 'cntpmts24_3658933L', 'commnoinclast6m_3546845L', 'maxdpdfrom6mto36m_3546853P', 'datefirstoffer_1144D', 'datelastunpaid_3546854D', 'daysoverduetolerancedd_3976961L', 'numinsttopaygr_769L', 'dtlastpmtallstes_4499206D', 'eir_270L', 'firstclxcampaign_1125D', 'firstdatedue_489D', 'lastactivateddate_801D', 'lastapplicationdate_877D', 'mean_creationdate_885D', 'max_num_group1', 'last_num_group1', 'max_num_group2_14', 'last_num_group2_14', 'lastapprcredamount_781A', 'lastapprdate_640D', 'lastdelinqdate_224D', 'lastrejectcredamount_222A', 'lastrejectdate_50D', 'maininc_215A', 'mastercontrelectronic_519L', 'mastercontrexist_109L', 'maxannuity_159A', 'maxdebt4_972A', 'maxdpdlast24m_143P', 'maxdpdlast3m_392P', 'maxdpdtolerance_374P', 'maxdbddpdlast1m_3658939P', 'maxdbddpdtollast12m_3658940P', 'maxdbddpdtollast6m_4187119P', 'maxdpdinstldate_3546855D', 'maxdpdinstlnum_3546846P', 'maxlnamtstart6m_4525199A', 'maxoutstandbalancel12m_4187113A', 'numinstpaidearly_338L', 'numinstpaidearly5d_1087L', 'numinstpaidlate1d_3546852L', 'numincomingpmts_3546848L', 'numinstlsallpaid_934L', 'numinstlswithdpd10_728L', 'numinstlswithoutdpd_562L', 'numinstpaid_4499208L', 'numinstpaidearly3d_3546850L', 'numinstregularpaidest_4493210L', 'numinstpaidearly5dest_4493211L', 'sumoutstandtotalest_4493215A', 'numinstpaidlastcontr_4325080L', 'numinstregularpaid_973L', 'pctinstlsallpaidearl3d_427L', 'pctinstlsallpaidlate1d_3546856L', 'pctinstlsallpaidlat10d_839L', 'pctinstlsallpaidlate4d_3546849L', 'pctinstlsallpaidlate6d_3546844L', 'pmtnum_254L', 'posfpd10lastmonth_333P', 'posfpd30lastmonth_3976960P', 'posfstqpd30lastmonth_3976962P', 'price_1097A', 'sumoutstandtotal_3546847A', 'totaldebt_9A', 'mean_actualdpd_943P', 'max_annuity_853A', 'mean_annuity_853A', 'max_credacc_credlmt_575A', 'max_credamount_590A', 'max_downpmt_134A', 'mean_credacc_credlmt_575A', 'mean_credamount_590A', 'mean_downpmt_134A', 'max_currdebt_94A', 'mean_currdebt_94A', 'max_mainoccupationinc_437A', 'mean_mainoccupationinc_437A', 'mean_maxdpdtolerance_577P', 'max_outstandingdebt_522A', 'mean_outstandingdebt_522A', 'last_actualdpd_943P', 'last_annuity_853A', 'last_credacc_credlmt_575A', 'last_credamount_590A', 'last_downpmt_134A', 'last_currdebt_94A', 'last_mainoccupationinc_437A', 'last_maxdpdtolerance_577P', 'last_outstandingdebt_522A', 'max_approvaldate_319D', 'mean_approvaldate_319D', 'max_dateactivated_425D', 'mean_dateactivated_425D', 'max_dtlastpmt_581D', 'mean_dtlastpmt_581D', 'max_dtlastpmtallstes_3545839D', 'mean_dtlastpmtallstes_3545839D', 'max_employedfrom_700D', 'max_firstnonzeroinstldate_307D', 'mean_firstnonzeroinstldate_307D', 'last_approvaldate_319D', 'last_creationdate_885D', 'last_dateactivated_425D', 'last_dtlastpmtallstes_3545839D', 'last_employedfrom_700D', 'last_firstnonzeroinstldate_307D', 'max_byoccupationinc_3656910L', 'max_childnum_21L', 'max_pmtnum_8L', 'last_pmtnum_8L', 'max_pmtamount_36A', 'last_pmtamount_36A', 'max_processingdate_168D', 'last_processingdate_168D', 'max_num_group1_5', 'mean_credlmt_230A', 'mean_credlmt_935A', 'mean_pmts_dpd_1073P', 'max_dpdmaxdatemonth_89T', 'max_dpdmaxdateyear_596T', 'max_pmts_dpd_303P', 'mean_dpdmax_757P', 'max_dpdmaxdatemonth_442T', 'max_dpdmaxdateyear_896T', 'mean_pmts_dpd_303P', 'mean_instlamount_768A', 'mean_monthlyinstlamount_332A', 'max_monthlyinstlamount_674A', 'mean_monthlyinstlamount_674A', 'mean_outstandingamount_354A', 'mean_outstandingamount_362A', 'mean_overdueamount_31A', 'mean_overdueamount_659A', 'max_numberofoverdueinstls_725L', 'mean_overdueamountmax2_14A', 'mean_totaloutstanddebtvalue_39A', 'mean_dateofcredend_289D', 'mean_dateofcredstart_739D', 'max_lastupdate_1112D', 'mean_lastupdate_1112D', 'max_numberofcontrsvalue_258L', 'max_numberofoverdueinstlmax_1039L', 'max_overdueamountmaxdatemonth_365T', 'max_overdueamountmaxdateyear_2T', 'mean_pmts_overdue_1140A', 'max_pmts_month_158T', 'max_pmts_year_1139T', 'mean_overdueamountmax2_398A', 'max_dateofcredend_353D', 'max_dateofcredstart_181D', 'mean_dateofcredend_353D', 'max_numberofoverdueinstlmax_1151L', 'mean_overdueamountmax_35A', 'max_overdueamountmaxdatemonth_284T', 'max_overdueamountmaxdateyear_994T', 'mean_pmts_overdue_1152A', 'max_residualamount_488A', 'mean_residualamount_856A', 'max_totalamount_6A', 'mean_totalamount_6A', 'mean_totalamount_996A', 'mean_totaldebtoverduevalue_718A', 'mean_totaloutstanddebtvalue_668A', 'max_numberofcontrsvalue_358L', 'max_dateofrealrepmt_138D', 'mean_dateofrealrepmt_138D', 'max_lastupdate_388D', 'mean_lastupdate_388D', 'max_numberofoverdueinstlmaxdat_148D', 'mean_numberofoverdueinstlmaxdat_641D', 'mean_overdueamountmax2date_1002D', 'max_overdueamountmax2date_1142D', 'last_refreshdate_3813885D', 'max_nominalrate_281L', 'max_nominalrate_498L', 'max_numberofinstls_229L', 'max_numberofinstls_320L', 'max_numberofoutstandinstls_520L', 'max_numberofoutstandinstls_59L', 'max_numberofoverdueinstls_834L', 'max_periodicityofpmts_1102L', 'max_periodicityofpmts_837L', 'last_num_group1_6', 'last_mainoccupationinc_384A', 'last_birth_259D', 'max_empl_employedfrom_271D', 'last_personindex_1023L', 'last_persontype_1072L', 'max_collater_valueofguarantee_1124L', 'max_collater_valueofguarantee_876L', 'max_pmts_month_706T', 'max_pmts_year_507T', 'last_pmts_month_158T', 'last_pmts_year_1139T', 'last_pmts_month_706T', 'last_pmts_year_507T', 'max_num_group1_13', 'max_num_group2_13', 'last_num_group2_13', 'max_num_group1_15', 'max_num_group2_15']\n",
      "276\n",
      "389\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_train, cat_cols = to_pandas(df_train)\n",
    "df_train = reduce_mem_usage(df_train)\n",
    "print(\"train data shape:\\t\", df_train.shape)\n",
    "nums=df_train.select_dtypes(exclude='category').columns\n",
    "from itertools import combinations, permutations\n",
    "#df_train=df_train[nums]\n",
    "nans_df = df_train[nums].isna()\n",
    "nans_groups={}\n",
    "for col in nums:\n",
    "    cur_group = nans_df[col].sum()\n",
    "    try:\n",
    "        nans_groups[cur_group].append(col)\n",
    "    except:\n",
    "        nans_groups[cur_group]=[col]\n",
    "del nans_df; x=gc.collect()\n",
    "\n",
    "def reduce_group(grps):\n",
    "    use = []\n",
    "    for g in grps:\n",
    "        mx = 0; vx = g[0]\n",
    "        for gg in g:\n",
    "            n = df_train[gg].nunique()\n",
    "            if n>mx:\n",
    "                mx = n\n",
    "                vx = gg\n",
    "            #print(str(gg)+'-'+str(n),', ',end='')\n",
    "        use.append(vx)\n",
    "        #print()\n",
    "    print('Use these',use)\n",
    "    return use\n",
    "\n",
    "def group_columns_by_correlation(matrix, threshold=0.8):\n",
    "    # 计算列之间的相关性\n",
    "    correlation_matrix = matrix.corr()\n",
    "\n",
    "    # 分组列\n",
    "    groups = []\n",
    "    remaining_cols = list(matrix.columns)\n",
    "    while remaining_cols:\n",
    "        col = remaining_cols.pop(0)\n",
    "        group = [col]\n",
    "        correlated_cols = [col]\n",
    "        for c in remaining_cols:\n",
    "            if correlation_matrix.loc[col, c] >= threshold:\n",
    "                group.append(c)\n",
    "                correlated_cols.append(c)\n",
    "        groups.append(group)\n",
    "        remaining_cols = [c for c in remaining_cols if c not in correlated_cols]\n",
    "    \n",
    "    return groups\n",
    "\n",
    "uses=[]\n",
    "for k,v in nans_groups.items():\n",
    "    if len(v)>1:\n",
    "            Vs = nans_groups[k]\n",
    "            #cross_features=list(combinations(Vs, 2))\n",
    "            #make_corr(Vs)\n",
    "            grps= group_columns_by_correlation(df_train[Vs], threshold=0.8)\n",
    "            use=reduce_group(grps)\n",
    "            uses=uses+use\n",
    "            #make_corr(use)\n",
    "    else:\n",
    "        uses=uses+v\n",
    "    print('####### NAN count =',k)\n",
    "print(uses)\n",
    "print(len(uses))\n",
    "uses=uses+list(df_train.select_dtypes(include='category').columns)\n",
    "print(len(uses))\n",
    "df_train=df_train[uses]\n",
    "# df_train.drop(['requesttype_4525192L_cnt','max_empl_employedtotal_800L_cnt', 'max_empl_industry_691L_cnt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5e632c2",
   "metadata": {
    "papermill": {
     "duration": 1.223499,
     "end_time": "2024-04-16T09:51:06.596920",
     "exception": false,
     "start_time": "2024-04-16T09:51:05.373421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df_train[\"target\"]\n",
    "weeks = df_train[\"WEEK_NUM\"]\n",
    "df_train= df_train.drop(columns=[\"target\", \"case_id\", \"WEEK_NUM\"])\n",
    "# df_train, y = SMOTE().fit_resample(df_train, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9163eeb3",
   "metadata": {
    "papermill": {
     "duration": 1722.395267,
     "end_time": "2024-04-16T10:19:49.000097",
     "exception": false,
     "start_time": "2024-04-16T09:51:06.604830",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's auc: 0.846298\n",
      "[400]\tvalid_0's auc: 0.850778\n",
      "[600]\tvalid_0's auc: 0.852371\n",
      "[800]\tvalid_0's auc: 0.853024\n",
      "[1000]\tvalid_0's auc: 0.853407\n",
      "[1200]\tvalid_0's auc: 0.853536\n",
      "[1400]\tvalid_0's auc: 0.853525\n",
      "Early stopping, best iteration is:\n",
      "[1333]\tvalid_0's auc: 0.853644\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's auc: 0.847201\n",
      "[400]\tvalid_0's auc: 0.851815\n",
      "[600]\tvalid_0's auc: 0.853374\n",
      "[800]\tvalid_0's auc: 0.853851\n",
      "[1000]\tvalid_0's auc: 0.854124\n",
      "Early stopping, best iteration is:\n",
      "[1063]\tvalid_0's auc: 0.854265\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's auc: 0.851982\n",
      "[400]\tvalid_0's auc: 0.856819\n",
      "[600]\tvalid_0's auc: 0.857987\n",
      "[800]\tvalid_0's auc: 0.85834\n",
      "[1000]\tvalid_0's auc: 0.858678\n",
      "[1200]\tvalid_0's auc: 0.858816\n",
      "[1400]\tvalid_0's auc: 0.858773\n",
      "Early stopping, best iteration is:\n",
      "[1311]\tvalid_0's auc: 0.858852\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's auc: 0.851561\n",
      "[400]\tvalid_0's auc: 0.856186\n",
      "[600]\tvalid_0's auc: 0.857453\n",
      "[800]\tvalid_0's auc: 0.858036\n",
      "[1000]\tvalid_0's auc: 0.858116\n",
      "Early stopping, best iteration is:\n",
      "[957]\tvalid_0's auc: 0.858171\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's auc: 0.84733\n",
      "[400]\tvalid_0's auc: 0.852202\n",
      "[600]\tvalid_0's auc: 0.85351\n",
      "[800]\tvalid_0's auc: 0.854195\n",
      "[1000]\tvalid_0's auc: 0.854477\n",
      "[1200]\tvalid_0's auc: 0.85457\n",
      "Early stopping, best iteration is:\n",
      "[1220]\tvalid_0's auc: 0.854604\n",
      "CV AUC scores:  [0.8536435020245055, 0.8542654013412985, 0.8588522170765014, 0.8581710117998722, 0.8546038545133967]\n",
      "Maximum CV AUC score:  0.8588522170765014\n"
     ]
    }
   ],
   "source": [
    "n_split = 5\n",
    "cv = StratifiedGroupKFold(n_splits=n_split, shuffle=False)\n",
    "\n",
    "params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"max_depth\": 10,  \n",
    "    \"learning_rate\": 0.05,\n",
    "    \"n_estimators\": 2000,  \n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"colsample_bynode\": 0.8,\n",
    "    \"verbose\": -1,\n",
    "    \"random_state\": 42,\n",
    "    \"reg_alpha\": 0.1,\n",
    "    \"reg_lambda\": 10,\n",
    "    \"extra_trees\":True,\n",
    "    'num_leaves':64,\n",
    "    \"sample_weight\":'balanced',\n",
    "    \"device\": \"cpu\", \n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "fitted_models = []\n",
    "cv_scores = []\n",
    "\n",
    "for idx_train, idx_valid in cv.split(df_train, y, groups=weeks):#   Because it takes a long time to divide the data set, \n",
    "    X_train, y_train = df_train.iloc[idx_train], y.iloc[idx_train]# each time the data set is divided, two models are trained to each other twice, which saves time.\n",
    "    X_valid, y_valid = df_train.iloc[idx_valid], y.iloc[idx_valid]\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set = [(X_valid, y_valid)],\n",
    "        callbacks = [lgb.log_evaluation(200), lgb.early_stopping(100)] )\n",
    "    fitted_models.append(model)\n",
    "    y_pred_valid = model.predict_proba(X_valid)[:,1]\n",
    "    auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "    cv_scores.append(auc_score)\n",
    "    \n",
    "print(\"CV AUC scores: \", cv_scores)\n",
    "print(\"Maximum CV AUC score: \", max(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cd1f68d",
   "metadata": {
    "papermill": {
     "duration": 0.916208,
     "end_time": "2024-04-16T10:19:49.928075",
     "exception": false,
     "start_time": "2024-04-16T10:19:49.011867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model done.\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "for i in range(n_split):\n",
    "    with open(f'home-credit-lgb/model_{i}.pkl', 'wb') as fout:\n",
    "       pkl.dump(fitted_models[i], fout)\n",
    "        \n",
    "print('saved model done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f892816e",
   "metadata": {
    "papermill": {
     "duration": 0.012338,
     "end_time": "2024-04-16T10:19:49.953095",
     "exception": false,
     "start_time": "2024-04-16T10:19:49.940757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e5e230f-c7f3-48fd-b4e6-17a15e9f4ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VotingModel(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, estimators):\n",
    "        super().__init__()\n",
    "        self.estimators = estimators\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_preds = [estimator.predict(X) for estimator in self.estimators]\n",
    "        return np.mean(y_preds, axis=0)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        y_preds = [estimator.predict_proba(X) for estimator in self.estimators]\n",
    "        return np.mean(y_preds, axis=0)\n",
    "\n",
    "model = VotingModel(fitted_models)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7921029,
     "sourceId": 50160,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1968.459747,
   "end_time": "2024-04-16T10:19:50.837373",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-16T09:47:02.377626",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
